{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OBJECTIVES\n",
    "This chapter will cover:\n",
    "\n",
    "1. Tidy data\n",
    "\n",
    "2. Concatenating data\n",
    "\n",
    "3. Merging data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a csv file for concat\n",
    "scientists = pd.DataFrame({\n",
    "\n",
    "    'Name': ['Rosaline Franklin', 'William Gosset'],\n",
    "\n",
    "    'Occupation': ['Chemist', 'Statistician'],\n",
    "\n",
    "    'Born': ['1920-07-25', '1876-06-13'],\n",
    "\n",
    "    'Died': ['1958-04-16', '1937-10-16'],\n",
    "\n",
    "    'Age': [37, 61]})\n",
    "\n",
    "print(scientists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.DataFrame({\n",
    "    'A' : ['a0','a1','a2','a3'],\n",
    "    'B' : ['b0','b1','b2','b3'],\n",
    "    'C' : ['c0','c1','c2','c3'],\n",
    "    'D' : ['d0','d1','d2','d3'],\n",
    "    })\n",
    "df2 = pd.DataFrame({\n",
    "    'A' : ['a4','a5','a6','a7'],\n",
    "    'B' : ['b4','b5','b6','b7'],\n",
    "    'C' : ['c4','c5','c6','c7'],\n",
    "    'D' : ['d4','d5','d6','d7'],\n",
    "    })\n",
    "df3 = pd.DataFrame({\n",
    "    'A' : ['a8','a9','a10','a11'],\n",
    "    'B' : ['b8','b9','b10','b11'],\n",
    "    'C' : ['c8','c9','c10','c11'],\n",
    "    'D' : ['d8','d9','d10','d11'],\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D\n",
      "0  a0  b0  c0  d0\n",
      "1  a1  b1  c1  d1\n",
      "2  a2  b2  c2  d2\n",
      "3  a3  b3  c3  d3\n",
      "    A   B   C   D\n",
      "0  a4  b4  c4  d4\n",
      "1  a5  b5  c5  d5\n",
      "2  a6  b6  c6  d6\n",
      "3  a7  b7  c7  d7\n",
      "     A    B    C    D\n",
      "0   a8   b8   c8   d8\n",
      "1   a9   b9   c9   d9\n",
      "2  a10  b10  c10  d10\n",
      "3  a11  b11  c11  d11\n"
     ]
    }
   ],
   "source": [
    "print(df1)\n",
    "print(df2)\n",
    "print(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B    C    D\n",
      "0   a0   b0   c0   d0\n",
      "1   a1   b1   c1   d1\n",
      "2   a2   b2   c2   d2\n",
      "3   a3   b3   c3   d3\n",
      "0   a4   b4   c4   d4\n",
      "1   a5   b5   c5   d5\n",
      "2   a6   b6   c6   d6\n",
      "3   a7   b7   c7   d7\n",
      "0   a8   b8   c8   d8\n",
      "1   a9   b9   c9   d9\n",
      "2  a10  b10  c10  d10\n",
      "3  a11  b11  c11  d11\n"
     ]
    }
   ],
   "source": [
    "# Stacking the dataframes on top of each other uses the concat function in Pandas. \n",
    "# All of the dataframes to be concatenated are passed in a list.\n",
    "\n",
    "row_concat = pd.concat([df1, df2, df3])\n",
    "\n",
    "print(row_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "A    a3\n",
      "B    b3\n",
      "C    c3\n",
      "D    d3\n",
      "Name: 3, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# subset the fourth row of the concatenated dataframe\n",
    "\n",
    "subset_row = row_concat.iloc[3,]\n",
    "print(type(subset_row))\n",
    "print(subset_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    n1\n",
      "1    n2\n",
      "2    n3\n",
      "3    n4\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# create a new row of data\n",
    "\n",
    "new_row_series = pd.Series(['n1', 'n2', 'n3', 'n4'])\n",
    "\n",
    "print(new_row_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B    C    D    0\n",
      "0   a0   b0   c0   d0  NaN\n",
      "1   a1   b1   c1   d1  NaN\n",
      "2   a2   b2   c2   d2  NaN\n",
      "3   a3   b3   c3   d3  NaN\n",
      "0  NaN  NaN  NaN  NaN   n1\n",
      "1  NaN  NaN  NaN  NaN   n2\n",
      "2  NaN  NaN  NaN  NaN   n3\n",
      "3  NaN  NaN  NaN  NaN   n4\n"
     ]
    }
   ],
   "source": [
    "# attempt to add the new row to a dataframe\n",
    "\n",
    "print(pd.concat([df1, new_row_series]))\n",
    "\n",
    "# its added as a new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D\n",
      "0  n1  n2  n3  n4\n"
     ]
    }
   ],
   "source": [
    "# note the double brackets\n",
    "\n",
    "new_row_df = pd.DataFrame([['n1', 'n2', 'n3', 'n4']],\n",
    "                          columns=['A', 'B', 'C', 'D'])\n",
    "\n",
    "# Change one the column's name and check the results after concating\n",
    "print(new_row_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D\n",
      "0  a0  b0  c0  d0\n",
      "1  a1  b1  c1  d1\n",
      "2  a2  b2  c2  d2\n",
      "3  a3  b3  c3  d3\n",
      "0  n1  n2  n3  n4\n"
     ]
    }
   ],
   "source": [
    "print(pd.concat([df1, new_row_df]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D\n",
      "0  a0  b0  c0  d0\n",
      "1  a1  b1  c1  d1\n",
      "2  a2  b2  c2  d2\n",
      "3  a3  b3  c3  d3\n",
      "0  a4  b4  c4  d4\n",
      "1  a5  b5  c5  d5\n",
      "2  a6  b6  c6  d6\n",
      "3  a7  b7  c7  d7\n"
     ]
    }
   ],
   "source": [
    "# appending dataframes\n",
    "print(df1.append(df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "    A   B   C   D\n",
      "0  a0  b0  c0  d0\n",
      "1  a1  b1  c1  d1\n",
      "2  a2  b2  c2  d2\n",
      "3  a3  b3  c3  d3\n",
      "0  n1  n2  n3  n4\n"
     ]
    }
   ],
   "source": [
    "# Using a single-row DataFrame:\n",
    "\n",
    "print(type(new_row_df))\n",
    "\n",
    "print(df1.append(new_row_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D\n",
      "0  a0  b0  c0  d0\n",
      "1  a1  b1  c1  d1\n",
      "2  a2  b2  c2  d2\n",
      "3  a3  b3  c3  d3\n",
      "4  n1  n2  n3  n4\n"
     ]
    }
   ],
   "source": [
    "# Using a Python dictionary:\n",
    "data_dict = {'A': 'n1',\n",
    "             'B': 'n2',\n",
    "             'C': 'n3',\n",
    "             'D': 'n4'\n",
    "             #'E': 'n5'\n",
    "              }\n",
    "\n",
    "\n",
    "\n",
    "print(df1.append(data_dict, ignore_index=True))\n",
    "# try with ignore_index = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      A    B    C    D\n",
      "0    a0   b0   c0   d0\n",
      "1    a1   b1   c1   d1\n",
      "2    a2   b2   c2   d2\n",
      "3    a3   b3   c3   d3\n",
      "4    a4   b4   c4   d4\n",
      "5    a5   b5   c5   d5\n",
      "6    a6   b6   c6   d6\n",
      "7    a7   b7   c7   d7\n",
      "8    a8   b8   c8   d8\n",
      "9    a9   b9   c9   d9\n",
      "10  a10  b10  c10  d10\n",
      "11  a11  b11  c11  d11\n"
     ]
    }
   ],
   "source": [
    "row_concat_i = pd.concat([df1, df2, df3], ignore_index=True)\n",
    "\n",
    "print(row_concat_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B    C    D\n",
      "0   a0   b0   c0   d0\n",
      "1   a1   b1   c1   d1\n",
      "2   a2   b2   c2   d2\n",
      "3   a3   b3   c3   d3\n",
      "0   a4   b4   c4   d4\n",
      "1   a5   b5   c5   d5\n",
      "2   a6   b6   c6   d6\n",
      "3   a7   b7   c7   d7\n",
      "0   a8   b8   c8   d8\n",
      "1   a9   b9   c9   d9\n",
      "2  a10  b10  c10  d10\n",
      "3  a11  b11  c11  d11\n"
     ]
    }
   ],
   "source": [
    "row_concat_i = pd.concat([df1, df2, df3], ignore_index=False)\n",
    "\n",
    "print(row_concat_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  No duplicate columns names\n",
      "\n",
      "   0   1   2   3   4   5   6   7    8    9    10   11\n",
      "0  a0  b0  c0  d0  a4  b4  c4  d4   a8   b8   c8   d8\n",
      "1  a1  b1  c1  d1  a5  b5  c5  d5   a9   b9   c9   d9\n",
      "2  a2  b2  c2  d2  a6  b6  c6  d6  a10  b10  c10  d10\n",
      "3  a3  b3  c3  d3  a7  b7  c7  d7  a11  b11  c11  d11\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n  No duplicate columns names\\n\")\n",
    "\n",
    "col_concat = pd.concat([df1, df2, df3], axis=1,ignore_index=True)\n",
    "\n",
    "print(col_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D   A   B   C   D    A    B    C    D\n",
      "0  a0  b0  c0  d0  a4  b4  c4  d4   a8   b8   c8   d8\n",
      "1  a1  b1  c1  d1  a5  b5  c5  d5   a9   b9   c9   d9\n",
      "2  a2  b2  c2  d2  a6  b6  c6  d6  a10  b10  c10  d10\n",
      "3  a3  b3  c3  d3  a7  b7  c7  d7  a11  b11  c11  d11\n"
     ]
    }
   ],
   "source": [
    "# column wise concatenation\n",
    "\n",
    "col_concat = pd.concat([df1, df2, df3], axis=1,ignore_index=False)\n",
    "\n",
    "print(col_concat)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   A    A\n",
      "0  a0  a4   a8\n",
      "1  a1  a5   a9\n",
      "2  a2  a6  a10\n",
      "3  a3  a7  a11\n"
     ]
    }
   ],
   "source": [
    "print(col_concat['A'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D   A   B   C   D    A    B    C    D new_col_list\n",
      "0  a0  b0  c0  d0  a4  b4  c4  d4   a8   b8   c8   d8           n1\n",
      "1  a1  b1  c1  d1  a5  b5  c5  d5   a9   b9   c9   d9           n2\n",
      "2  a2  b2  c2  d2  a6  b6  c6  d6  a10  b10  c10  d10           n3\n",
      "3  a3  b3  c3  d3  a7  b7  c7  d7  a11  b11  c11  d11           n4\n"
     ]
    }
   ],
   "source": [
    "col_concat['new_col_list'] = ['n1', 'n2', 'n3', 'n4']\n",
    "\n",
    "print(col_concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Concatenation With Different Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D\n",
      "0  a0  b0  c0  d0\n",
      "1  a1  b1  c1  d1\n",
      "2  a2  b2  c2  d2\n",
      "3  a3  b3  c3  d3\n",
      "    E   F   G   H\n",
      "0  a4  b4  c4  d4\n",
      "1  a5  b5  c5  d5\n",
      "2  a6  b6  c6  d6\n",
      "3  a7  b7  c7  d7\n",
      "     A    C    F    H\n",
      "0   a8   b8   c8   d8\n",
      "1   a9   b9   c9   d9\n",
      "2  a10  b10  c10  d10\n",
      "3  a11  b11  c11  d11\n"
     ]
    }
   ],
   "source": [
    "df1.columns = ['A', 'B', 'C', 'D']\n",
    "\n",
    "df2.columns = ['E', 'F', 'G', 'H']\n",
    "\n",
    "df3.columns = ['A', 'C', 'F', 'H']\n",
    "\n",
    "print(df1)\n",
    "print(df2)\n",
    "print(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B    C    D    E    F    G    H\n",
      "0   a0   b0   c0   d0  NaN  NaN  NaN  NaN\n",
      "1   a1   b1   c1   d1  NaN  NaN  NaN  NaN\n",
      "2   a2   b2   c2   d2  NaN  NaN  NaN  NaN\n",
      "3   a3   b3   c3   d3  NaN  NaN  NaN  NaN\n",
      "0  NaN  NaN  NaN  NaN   a4   b4   c4   d4\n",
      "1  NaN  NaN  NaN  NaN   a5   b5   c5   d5\n",
      "2  NaN  NaN  NaN  NaN   a6   b6   c6   d6\n",
      "3  NaN  NaN  NaN  NaN   a7   b7   c7   d7\n",
      "0   a8  NaN   b8  NaN  NaN   c8  NaN   d8\n",
      "1   a9  NaN   b9  NaN  NaN   c9  NaN   d9\n",
      "2  a10  NaN  b10  NaN  NaN  c10  NaN  d10\n",
      "3  a11  NaN  b11  NaN  NaN  c11  NaN  d11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\babas\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=True'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass sort=False\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "row_concat = pd.concat([df1, df2, df3])\n",
    "\n",
    "print(row_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: [0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "print(pd.concat([df1, df2, df3], join='inner'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B    C    D    F    H\n",
      "0   a0   b0   c0   d0  NaN  NaN\n",
      "1   a1   b1   c1   d1  NaN  NaN\n",
      "2   a2   b2   c2   d2  NaN  NaN\n",
      "3   a3   b3   c3   d3  NaN  NaN\n",
      "0   a8  NaN   b8  NaN   c8   d8\n",
      "1   a9  NaN   b9  NaN   c9   d9\n",
      "2  a10  NaN  b10  NaN  c10  d10\n",
      "3  a11  NaN  b11  NaN  c11  d11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\babas\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=True'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass sort=False\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "print(pd.concat([df1,df3]))#, ignore_index=False, join='inner'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    C\n",
      "0   a0   c0\n",
      "1   a1   c1\n",
      "2   a2   c2\n",
      "3   a3   c3\n",
      "0   a8   b8\n",
      "1   a9   b9\n",
      "2  a10  b10\n",
      "3  a11  b11\n"
     ]
    }
   ],
   "source": [
    "print(pd.concat([df1,df3], ignore_index=False, join='inner'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.index = [0, 1, 2, 3]\n",
    "\n",
    "df2.index = [4, 5, 6, 7]\n",
    "\n",
    "df3.index = [0, 2, 5, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D\n",
      "0  a0  b0  c0  d0\n",
      "1  a1  b1  c1  d1\n",
      "2  a2  b2  c2  d2\n",
      "3  a3  b3  c3  d3\n",
      "    E   F   G   H\n",
      "4  a4  b4  c4  d4\n",
      "5  a5  b5  c5  d5\n",
      "6  a6  b6  c6  d6\n",
      "7  a7  b7  c7  d7\n",
      "     A    C    F    H\n",
      "0   a8   b8   c8   d8\n",
      "2   a9   b9   c9   d9\n",
      "5  a10  b10  c10  d10\n",
      "7  a11  b11  c11  d11\n"
     ]
    }
   ],
   "source": [
    "print(df1)\n",
    "print(df2)\n",
    "print(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B    C    D    E    F    G    H    A    C    F    H\n",
      "0   a0   b0   c0   d0  NaN  NaN  NaN  NaN   a8   b8   c8   d8\n",
      "1   a1   b1   c1   d1  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
      "2   a2   b2   c2   d2  NaN  NaN  NaN  NaN   a9   b9   c9   d9\n",
      "3   a3   b3   c3   d3  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
      "4  NaN  NaN  NaN  NaN   a4   b4   c4   d4  NaN  NaN  NaN  NaN\n",
      "5  NaN  NaN  NaN  NaN   a5   b5   c5   d5  a10  b10  c10  d10\n",
      "6  NaN  NaN  NaN  NaN   a6   b6   c6   d6  NaN  NaN  NaN  NaN\n",
      "7  NaN  NaN  NaN  NaN   a7   b7   c7   d7  a11  b11  c11  d11\n"
     ]
    }
   ],
   "source": [
    "col_concat = pd.concat([df1, df2, df3], axis=1)\n",
    "\n",
    "print(col_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D   A   C   F   H\n",
      "0  a0  b0  c0  d0  a8  b8  c8  d8\n",
      "2  a2  b2  c2  d2  a9  b9  c9  d9\n"
     ]
    }
   ],
   "source": [
    "print(pd.concat([df1, df3], axis=1, join='inner'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ident  personal    family\n",
      "0      dyer   William      Dyer\n",
      "1        pb     Frank   Pabodie\n",
      "2      lake  Anderson      Lake\n",
      "3       roe  Valentia   Roerich\n",
      "4  danforth     Frank  Danforth\n"
     ]
    }
   ],
   "source": [
    "#  MERGING MULTIPLE DATA SETS\n",
    "\n",
    "person = pd.DataFrame({\n",
    "    'ident' : ['dyer','pb','lake','roe','danforth'],\n",
    "    'personal' : ['William','Frank','Anderson','Valentia','Frank'],\n",
    "    'family':['Dyer','Pabodie','Lake','Roerich','Danforth']\n",
    "})\n",
    "print(person)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    name    lat    long\n",
      "0   DR-1 -49.85 -128.57\n",
      "1   DR-3 -47.15 -126.72\n",
      "2  MSK-4 -48.87 -123.40\n"
     ]
    }
   ],
   "source": [
    "site = pd.DataFrame({\n",
    "    'name' : ['DR-1','DR-3','MSK-4'],\n",
    "    'lat' : [-49.85,-47.15,-48.87],\n",
    "    'long': [-128.57,-126.72,-123.40]\n",
    "})\n",
    "print(site)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   ident   site       dated\n",
    "\n",
    "0    619   DR-1  1927-02-08\n",
    "\n",
    "1    622   DR-1  1927-02-10\n",
    "\n",
    "2    734   DR-3  1939-01-07\n",
    "\n",
    "3    735   DR-3  1930-01-12\n",
    "\n",
    "4    751   DR-3  1930-02-26\n",
    "\n",
    "5    752   DR-3         NaN\n",
    "\n",
    "6    837  MSK-4  1932-01-14\n",
    "\n",
    "7    844   DR-1  1932-03-22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ident   site       dated\n",
      "0    619   DR-1  1927-02-08\n",
      "1    622   DR-1  1927-02-10\n",
      "2    734   DR-3  1939-01-07\n",
      "3    735   DR-3  1930-01-12\n",
      "4    751   DR-3  1930-02-26\n",
      "5    752   DR-3          NA\n",
      "6    837  MSK-4  1932-01-14\n",
      "7    844   DR-1  1932-03-22\n"
     ]
    }
   ],
   "source": [
    "visited = pd.DataFrame({\n",
    "    'ident' :[619,622,734,735,751,752,837,844],\n",
    "    'site'  :['DR-1','DR-1','DR-3','DR-3','DR-3','DR-3','MSK-4','DR-1'],\n",
    "    'dated' : ['1927-02-08','1927-02-10','1939-01-07','1930-01-12','1930-02-26','NA','1932-01-14','1932-03-22']\n",
    "})\n",
    "print(visited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " taken person quant  reading\n",
    "\n",
    "0     619   dyer   rad    9.82\n",
    "1     619   dyer   sal    0.13\n",
    "2     622   dyer   rad    7.80\n",
    "3     622   dyer   sal    0.09\n",
    "4     734     pb   rad    8.41\n",
    "5     734   lake   sal    0.05\n",
    "6     734     pb  temp  -21.50\n",
    "7     735     pb   rad    7.22\n",
    "8     735    NaN   sal    0.06\n",
    "9     735    NaN  temp  -26.00\n",
    "10    751     pb   rad    4.35\n",
    "11    751     pb  temp  -18.50\n",
    "12    751   lake   sal    0.10\n",
    "13    752   lake   rad    2.19\n",
    "14    752   lake   sal    0.09\n",
    "15    752   lake  temp  -16.00\n",
    "16    752    roe   sal   41.60\n",
    "17    837   lake   rad    1.46\n",
    "18    837   lake   sal    0.21\n",
    "19    837    roe   sal   22.50\n",
    "20    844    roe   rad   11.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    taken person quant  reading\n",
      "0     619   dyer   rad     9.82\n",
      "1     619   dyer   sal     0.13\n",
      "2     622   dyer   rad     7.80\n",
      "3     622   dyer   sal     0.09\n",
      "4     734     pb   rad     8.41\n",
      "5     734   lake   sal     0.05\n",
      "6     734     pb  temp   -21.50\n",
      "7     735     pb   rad     7.22\n",
      "8     735     NA   sal     0.06\n",
      "9     735     NA  temp   -26.00\n",
      "10    751     pb   rad     4.35\n",
      "11    751     pb  temp   -18.50\n",
      "12    751   lake   sal     0.10\n",
      "13    752   lake   rad     2.19\n",
      "14    752   lake   sal     0.09\n",
      "15    752   lake  temp   -16.00\n",
      "16    752    roe   sal    41.60\n",
      "17    837   lake   rad     1.46\n",
      "18    837   lake   sal     0.21\n",
      "19    837    roe   sal    22.50\n",
      "20    844    roe   rad    11.25\n"
     ]
    }
   ],
   "source": [
    "survey = pd.DataFrame({\n",
    "    'taken' : [619,619,622,622,734,734,734,735,735,735,751,751,751,752,752,752,752,837,837,837,844],\n",
    "    'person' :['dyer','dyer','dyer','dyer','pb','lake','pb','pb','NA','NA','pb','pb','lake','lake','lake','lake','roe','lake'\\\n",
    "              ,'lake','roe','roe'],\n",
    "    'quant' :['rad','sal','rad','sal','rad','sal','temp','rad','sal','temp','rad','temp','sal','rad','sal','temp',\n",
    "             'sal','rad','sal','sal','rad'],\n",
    "    'reading':[9.82,0.13,7.80,0.09,8.41,0.05,-21.50,7.22,0.06,-26.00,4.35,-18.50,0.10,2.19,0.09,-16.00,41.60,1.46,\\\n",
    "               0.21,22.50,11.25]\n",
    "})\n",
    "print(survey)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table - How the Pandas how Parameter Relates to SQL\n",
    "\n",
    "Pandas SQL Description\n",
    "\n",
    "left left outer Keep all the keys from the left\n",
    "\n",
    "right right outer Keep all the keys from the right\n",
    "\n",
    "outer full outer Keep all the keys from both left and right\n",
    "\n",
    "inner inner Keep only the keys that exist in both left and right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-to-One Merge\n",
    "visited_subset = visited.loc[[0, 2, 6], ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ident   site       dated\n",
      "0    619   DR-1  1927-02-08\n",
      "2    734   DR-3  1939-01-07\n",
      "6    837  MSK-4  1932-01-14\n"
     ]
    }
   ],
   "source": [
    "print(visited_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    name    lat    long  ident   site       dated\n",
      "0   DR-1 -49.85 -128.57    619   DR-1  1927-02-08\n",
      "1   DR-3 -47.15 -126.72    734   DR-3  1939-01-07\n",
      "2  MSK-4 -48.87 -123.40    837  MSK-4  1932-01-14\n"
     ]
    }
   ],
   "source": [
    "# the default value for 'how' is 'inner'\n",
    "\n",
    "# so it doesn't need to be specified\n",
    "\n",
    "o2o_merge = site.merge(visited_subset,left_on='name', right_on='site')\n",
    "\n",
    "print(o2o_merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    name    lat    long  ident   site       dated\n",
      "0   DR-1 -49.85 -128.57    619   DR-1  1927-02-08\n",
      "1   DR-1 -49.85 -128.57    622   DR-1  1927-02-10\n",
      "2   DR-1 -49.85 -128.57    844   DR-1  1932-03-22\n",
      "3   DR-3 -47.15 -126.72    734   DR-3  1939-01-07\n",
      "4   DR-3 -47.15 -126.72    735   DR-3  1930-01-12\n",
      "5   DR-3 -47.15 -126.72    751   DR-3  1930-02-26\n",
      "6   DR-3 -47.15 -126.72    752   DR-3          NA\n",
      "7  MSK-4 -48.87 -123.40    837  MSK-4  1932-01-14\n"
     ]
    }
   ],
   "source": [
    "# Many-to-One Merge\n",
    "m2o_merge = site.merge(visited, left_on='name', right_on='site')\n",
    "\n",
    "print(m2o_merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ident  personal   family  taken person quant  reading\n",
      "0   dyer   William     Dyer    619   dyer   rad     9.82\n",
      "1   dyer   William     Dyer    619   dyer   sal     0.13\n",
      "2   dyer   William     Dyer    622   dyer   rad     7.80\n",
      "3   dyer   William     Dyer    622   dyer   sal     0.09\n",
      "4     pb     Frank  Pabodie    734     pb   rad     8.41\n",
      "5     pb     Frank  Pabodie    734     pb  temp   -21.50\n",
      "6     pb     Frank  Pabodie    735     pb   rad     7.22\n",
      "7     pb     Frank  Pabodie    751     pb   rad     4.35\n",
      "8     pb     Frank  Pabodie    751     pb  temp   -18.50\n",
      "9   lake  Anderson     Lake    734   lake   sal     0.05\n",
      "10  lake  Anderson     Lake    751   lake   sal     0.10\n",
      "11  lake  Anderson     Lake    752   lake   rad     2.19\n",
      "12  lake  Anderson     Lake    752   lake   sal     0.09\n",
      "13  lake  Anderson     Lake    752   lake  temp   -16.00\n",
      "14  lake  Anderson     Lake    837   lake   rad     1.46\n",
      "15  lake  Anderson     Lake    837   lake   sal     0.21\n",
      "16   roe  Valentia  Roerich    752    roe   sal    41.60\n",
      "17   roe  Valentia  Roerich    837    roe   sal    22.50\n",
      "18   roe  Valentia  Roerich    844    roe   rad    11.25\n"
     ]
    }
   ],
   "source": [
    "# Many-to-Many Merge\n",
    "ps = person.merge(survey, left_on='ident', right_on='person')\n",
    "\n",
    "vs = visited.merge(survey, left_on='ident', right_on='taken')\n",
    "\n",
    "print(ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ident   site       dated  taken person quant  reading\n",
      "0     619   DR-1  1927-02-08    619   dyer   rad     9.82\n",
      "1     619   DR-1  1927-02-08    619   dyer   sal     0.13\n",
      "2     622   DR-1  1927-02-10    622   dyer   rad     7.80\n",
      "3     622   DR-1  1927-02-10    622   dyer   sal     0.09\n",
      "4     734   DR-3  1939-01-07    734     pb   rad     8.41\n",
      "5     734   DR-3  1939-01-07    734   lake   sal     0.05\n",
      "6     734   DR-3  1939-01-07    734     pb  temp   -21.50\n",
      "7     735   DR-3  1930-01-12    735     pb   rad     7.22\n",
      "8     735   DR-3  1930-01-12    735     NA   sal     0.06\n",
      "9     735   DR-3  1930-01-12    735     NA  temp   -26.00\n",
      "10    751   DR-3  1930-02-26    751     pb   rad     4.35\n",
      "11    751   DR-3  1930-02-26    751     pb  temp   -18.50\n",
      "12    751   DR-3  1930-02-26    751   lake   sal     0.10\n",
      "13    752   DR-3          NA    752   lake   rad     2.19\n",
      "14    752   DR-3          NA    752   lake   sal     0.09\n",
      "15    752   DR-3          NA    752   lake  temp   -16.00\n",
      "16    752   DR-3          NA    752    roe   sal    41.60\n",
      "17    837  MSK-4  1932-01-14    837   lake   rad     1.46\n",
      "18    837  MSK-4  1932-01-14    837   lake   sal     0.21\n",
      "19    837  MSK-4  1932-01-14    837    roe   sal    22.50\n",
      "20    844   DR-1  1932-03-22    844    roe   rad    11.25\n"
     ]
    }
   ],
   "source": [
    "print(vs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_vs = ps.merge(vs,left_on=['ident', 'taken', 'quant', 'reading'],right_on=['person', 'ident', 'quant', 'reading'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ident_x           dyer\n",
      "personal       William\n",
      "family            Dyer\n",
      "taken_x            619\n",
      "person_x          dyer\n",
      "quant              rad\n",
      "reading           9.82\n",
      "ident_y            619\n",
      "site              DR-1\n",
      "dated       1927-02-08\n",
      "taken_y            619\n",
      "person_y          dyer\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(ps_vs.loc[0, ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
